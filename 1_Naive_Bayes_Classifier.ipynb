{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2bac82f",
   "metadata": {},
   "source": [
    "# Task 1: Theory Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6eba20",
   "metadata": {},
   "source": [
    "Ques.1. What is the core assumption of Naive Bayes?\n",
    "\n",
    "Ans.1. The core assumption of Naive Bayes is that all features are conditionally independent of each other given the class label. This means the presence or absence of one feature does not affect the presence or absence of another, simplifying the probability computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a30266c",
   "metadata": {},
   "source": [
    "Ques.2. Differentiate between GaussianNB, MultinomialNB, and BernoulliNB?\n",
    "\n",
    "Ans.2. \n",
    "\n",
    "GaussianNB assumes that features follow a normal (Gaussian) distribution and is best suited for continuous data.\n",
    "\n",
    "MultinomialNB works with discrete count data, such as word frequencies in text classification.\n",
    "\n",
    "BernoulliNB is used when features are binary (0 or 1), indicating presence or absence of a feature, like in spam filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455ff09a",
   "metadata": {},
   "source": [
    "Ques.3. Why is Naive Bayes considered suitable for high-dimensional data?\n",
    "\n",
    "Ans.3. Naive Bayes is computationally efficient and scales well to high-dimensional data because it assumes feature independence, allowing it to learn parameters from each feature individually. This makes it especially useful for tasks like text classification where feature spaces (like vocabulary size) can be very large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6755fe7",
   "metadata": {},
   "source": [
    "# Task 2: Spam Detection using MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baaa551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "Confusion Matrix:\n",
      "[[132   0]\n",
      " [  0  16]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "df = pd.read_csv(\"email.csv\", sep='\\t', header=None, names=[\"label\", \"message\"])\n",
    "\n",
    "df.dropna(subset=['message'], inplace=True)\n",
    "\n",
    "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['message'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_vec, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09779363",
   "metadata": {},
   "source": [
    "# Task 3: GaussianNB with Iris or Wine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ca95e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB Evaluation:\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Model Accuracy Comparison:\n",
      "GaussianNB Accuracy: 1.0000\n",
      "Logistic Regression Accuracy: 1.0000\n",
      "Decision Tree Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred_nb = gnb.predict(X_test)\n",
    "\n",
    "print(\"GaussianNB Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb, target_names=iris.target_names))\n",
    "\n",
    "lr = LogisticRegression(max_iter=200)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "print(\"Model Accuracy Comparison:\")\n",
    "print(f\"GaussianNB Accuracy: {accuracy_score(y_test, y_pred_nb):.4f}\")\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"Decision Tree Accuracy: {accuracy_score(y_test, y_pred_dt):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fc7e17",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "<h2>Thank You!</h2>\n",
    "\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
